{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "- try adding `section['page']['title']` and `section['page']['summary']` to `get_section_content`, to better align all sections from a page in meaning\n",
    "- assign topics to pages\n",
    "- fix document visualizations / topic lengths\n",
    "- try plugging in LangChain\n",
    "- add option to filter model to just certain domains from `pages-all.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import pickle\n",
    "import jsonlines\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()]\n",
    ")\n",
    "\n",
    "embeddings_location = 'rest_embeddings.pkl'\n",
    "raw_jsonl_data_location = '/tmp/pages-all.jsonl'\n",
    "\n",
    "# def getSectionContent(section):\n",
    "#     return section['page']['title'].replace('\\n', ' ').strip() + ' ' + section['page']['summary'].replace('\\n', ' ').strip() + ' ' + section['content'].replace('\\n', ' ').strip()\n",
    "\n",
    "def getSectionContent(section):\n",
    "    return section['content'].replace('\\n', ' ').strip()\n",
    "\n",
    "if not os.path.exists(embeddings_location):\n",
    "    print('Creating embeddings for knowledge base.')\n",
    "    sections = []\n",
    "    with jsonlines.open(raw_jsonl_data_location, 'r') as pages:\n",
    "        for page in pages:\n",
    "            for page_section in page['sections']:\n",
    "                section = dict()\n",
    "                section['page'] = dict()\n",
    "                section['page']['url'] = page['url']\n",
    "                section['page']['title'] = page['title']\n",
    "                section['page']['summary'] = page['summaries']['sbert']\n",
    "                section['content'] = page_section['content']['raw']\n",
    "                section['tokens'] = page_section['tokens']\n",
    "                sections.append(section)\n",
    "\n",
    "    passages = []\n",
    "    passages.extend(map(getSectionContent, sections))\n",
    "    print('Passages:', len(passages))\n",
    "    \n",
    "    bi_encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    bi_encoder.max_seq_length = 350\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning: No GPU found. Please add GPU to your notebook for better performance, falling back to CPU pooling.\")\n",
    "        pool = bi_encoder.start_multi_process_pool()\n",
    "        corpus_embeddings = bi_encoder.encode_multi_process(passages, pool)\n",
    "        bi_encoder.stop_multi_process_pool(pool)\n",
    "\n",
    "    else:\n",
    "        corpus_embeddings = bi_encoder.encode(passages)\n",
    "    print('Corpus embeddings created.')\n",
    "    \n",
    "    with open(embeddings_location, \"wb\") as writer:\n",
    "        pickle.dump({'sections': sections, 'embeddings': corpus_embeddings}, writer)\n",
    "    print(\"Embeddings stored on disc: \" + embeddings_location)\n",
    "\n",
    "else:\n",
    "    print(\"Loading pre-computed embeddings from disc: \" + embeddings_location)\n",
    "    with open(embeddings_location, \"rb\") as reader:\n",
    "        cache_data = pickle.load(reader)\n",
    "        sections = cache_data['sections']\n",
    "        corpus_embeddings = cache_data['embeddings']\n",
    "\n",
    "print('Corpus embedding size:', corpus_embeddings.shape)\n",
    "print('Sections:', len(sections))\n",
    "\n",
    "print(\"Successfully initialized / loaded embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-26 22:30:18 - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n",
      "2023-03-26 22:30:19 - Use pytorch device: cuda\n",
      "Passages: 87635\n",
      "Loading pre-computed BERTopic model from disc: rest-concatenated.model\n",
      "Loading pre-computed BERTopic topics, probs from disc: rest-concatenated-topics-probs.pkl\n",
      "Connect sections to assigned topics\n",
      "Successfully initialized / loaded BERTopic.\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "topics_location = 'rest-concatenated.model'\n",
    "topics_propbs_location = 'rest-concatenated-topics-probs.pkl'\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "embedding_model.max_seq_length = 350\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with \n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "    umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "    hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "    vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "    ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "    representation_model=representation_model # Step 6 - (Optional) Fine-tune topic represenations\n",
    ")\n",
    "\n",
    "passages = []\n",
    "passages.extend(map(getSectionContent, sections))\n",
    "print('Passages:', len(passages))\n",
    "\n",
    "if not os.path.exists(topics_location) or not os.path.exists(topics_propbs_location):\n",
    "    print('Creating BERTopic model.')\n",
    "    topics, probs = topic_model.fit_transform(passages, corpus_embeddings)\n",
    "\n",
    "    topic_model.save(topics_location)\n",
    "    print(\"BERTopic model stored on disc: \" + topics_location)\n",
    "    with open(topics_propbs_location, \"wb\") as writer:\n",
    "        pickle.dump({'topics': topics, 'probs': probs}, writer)\n",
    "    print(\"BERTopic topics, probs stored on disc: \" + topics_location)\n",
    "else:\n",
    "    print(\"Loading pre-computed BERTopic model from disc: \" + topics_location)\n",
    "    topic_model = BERTopic.load(topics_location, embedding_model=embedding_model)\n",
    "\n",
    "    print(\"Loading pre-computed BERTopic topics, probs from disc: \" + topics_propbs_location)\n",
    "    with open(topics_propbs_location, \"rb\") as reader:\n",
    "        cache_data = pickle.load(reader)\n",
    "        topics = cache_data['topics']\n",
    "        probs = cache_data['probs']\n",
    "\n",
    "print(\"Connect sections to assigned topics\")\n",
    "topic_sections = {topic: [] for topic in set(topics)}\n",
    "for topic, section in zip(topics, sections):\n",
    "    topic_sections[topic].append(section)\n",
    "\n",
    "print(\"Successfully initialized / loaded BERTopic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('focuses', 0.8161726),\n",
       " ('focus', 0.8118751),\n",
       " ('focusing', 0.80106676),\n",
       " ('focusable', 0.76633096),\n",
       " ('focused', 0.7578648),\n",
       " ('focuspropsdomattributesprops', 0.72573054),\n",
       " ('focusableelementmoves', 0.7060925),\n",
       " ('focusscope', 0.6712526),\n",
       " ('focusmanageroptions', 0.6543964),\n",
       " ('scope', 0.52648306)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['##### Focus[#](#Focus)',\n",
       " 'Keyboard Interactions#  Arrow keys, when focus is on selected tab, cycle selection to the next or previous tab Tab key, when focus is before the tab list, moves focus to the selected tab Tab key, when focus is on selected tab, moves focus into the selected tab’s associated tab panel or to the next focusable element on the page if that panel has no focusable elements Shift+Tab keys, when focus is on first element in a tab panel, move focus to the selected tab',\n",
       " 'Keyboard Interactions#  Arrow keys, when focus is on selected tab, cycle selection to the next or previous tab Tab key, when focus is before the tab list, moves focus to the selected tab Tab key, when focus is on selected tab, moves focus into the selected tab’s associated tab panel or to the next focusable element on the page if that panel has no focusable elements Shift+Tab keys, when focus is on first element in a tab panel, move focus to the selected tab']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_representative_docs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accessibilitylabel', 0.4855991),\n",
       " ('accessibledescribedby', 0.46398896),\n",
       " ('accessiblecontrols', 0.4491005),\n",
       " ('accessibleactivedescendant', 0.42917725),\n",
       " ('accessibleowns', 0.39517504),\n",
       " ('accessibility', 0.38991874),\n",
       " ('attribute', 0.37215942),\n",
       " ('labelhidden', 0.33763373),\n",
       " ('accessible', 0.31761557),\n",
       " ('loadingindicators', 0.31623024)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"accessibility\", top_n=5)\n",
    "topic_model.get_topic(similar_topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(corpus_embeddings)\n",
    "topic_model.visualize_documents(sections, reduced_embeddings=reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Apply 'Algorithm 1' to the ada-002 embeddings to make them isotropic, taken from the paper:\n",
    "# ALL-BUT-THE-TOP: SIMPLE AND EFFECTIVE POST- PROCESSING FOR WORD REPRESENTATIONS\n",
    "# Jiaqi Mu, Pramod Viswanath\n",
    "\n",
    "# This uses Principal Component Analysis (PCA) to 'evenly distribute' the embedding vectors (make them isotropic)\n",
    "# For more information on PCA, see https://jamesmccaffrey.wordpress.com/2021/07/16/computing-pca-using-numpy-without-scikit/\n",
    "\n",
    "\n",
    "# get the file pointer of the pickle containing the embeddings\n",
    "fp = open('/path/to/your/data/Embedding-Latest.pkl', 'rb')\n",
    "\n",
    "\n",
    "# the embedding data here is a dict consisting of key / value pairs\n",
    "# the key is the hash of the message (SHA3-256), the value is the embedding from ada-002 (array of dimension 1536)\n",
    "# the hash can be used to lookup the orignal text in a database\n",
    "E = pickle.load(fp) # load the data into memory\n",
    "\n",
    "# seperate the keys (hashes) and values (embeddings) into seperate vectors\n",
    "K = list(E.keys()) # vector of all the hash values \n",
    "X = np.array(list(E.values())) # vector of all the embeddings, converted to numpy arrays\n",
    "\n",
    "\n",
    "# list the total number of embeddings\n",
    "# this can be truncated if there are too many embeddings to do PCA on\n",
    "print(f\"Total number of embeddings: {len(X)}\")\n",
    "\n",
    "# get dimension of embeddings, used later\n",
    "Dim = len(X[0])\n",
    "\n",
    "# flash out the first few embeddings\n",
    "print(\"First two embeddings are: \")\n",
    "print(X[0]) \n",
    "print(f\"First embedding length: {len(X[0])}\")\n",
    "print(X[1])\n",
    "print(f\"Second embedding length: {len(X[1])}\")\n",
    "\n",
    "\n",
    "# compute the mean of all the embeddings, and flash the result\n",
    "mu = np.mean(X, axis=0) # same as mu in paper\n",
    "print(f\"Mean embedding vector: {mu}\")\n",
    "print(f\"Mean embedding vector length: {len(mu)}\")\n",
    "\n",
    "\n",
    "# subtract the mean vector from each embedding vector ... vectorized in numpy\n",
    "X_tilde = X - mu # same as v_tilde(w) in paper\n",
    "\n",
    "\n",
    "\n",
    "# do the heavy lifting of extracting the principal components\n",
    "# note that this is a function of the embeddings you currently have here, and this set may grow over time\n",
    "# therefore the PCA basis vectors may change over time, and your final isotropic embeddings may drift over time\n",
    "# but the drift should stabilize after you have extracted enough embedding data to characterize the nature of the embedding engine\n",
    "print(f\"Performing PCA on the normalized embeddings ...\")\n",
    "pca = sklearn.decomposition.PCA()  # new object\n",
    "TICK = time.time() # start timer\n",
    "pca.fit(X_tilde) # do the heavy lifting!\n",
    "TOCK = time.time() # end timer\n",
    "DELTA = TOCK - TICK\n",
    "\n",
    "print(f\"PCA finished in {DELTA} seconds ...\")\n",
    "\n",
    "# dimensional reduction stage (the only hyperparameter)\n",
    "# pick max dimension of PCA components to express embddings\n",
    "# in general this is some integer less than or equal to the dimension of your embeddings\n",
    "# it could be set as a high percentile, say 95th percentile of pca.explained_variance_ratio_\n",
    "# but just hardcoding a constant here\n",
    "D = 15 # hyperparameter on dimension (out of 1536 for ada-002), paper recommeds D = Dim/100\n",
    "\n",
    "\n",
    "# form the set of v_prime(w), which is the final embedding\n",
    "# this could be vectorized in numpy to speed it up, but coding it directly here in a double for-loop to avoid errors and to be transparent\n",
    "E_prime = dict() # output dict of the new embeddings\n",
    "N = len(X_tilde)\n",
    "N10 = round(N/10)\n",
    "U = pca.components_ # set of PCA basis vectors, sorted by most significant to least significant\n",
    "print(f\"Shape of full set of PCA componenents {U.shape}\")\n",
    "U = U[0:D,:] # take the top D dimensions (or take them all if D is the size of the embedding vector)\n",
    "print(f\"Shape of downselected PCA componenents {U.shape}\")\n",
    "for ii in range(N):\n",
    "    v_tilde = X_tilde[ii]\n",
    "    v = X[ii]\n",
    "    v_projection = np.zeros(Dim) # start to build the projection\n",
    "    # project the original embedding onto the PCA basis vectors, use only first D dimensions\n",
    "    for jj in range(D):\n",
    "        u_jj = U[jj,:] # vector\n",
    "        v_jj = np.dot(u_jj,v) # scaler\n",
    "        v_projection += v_jj*u_jj # vector\n",
    "    v_prime = v_tilde - v_projection # final embedding vector\n",
    "    v_prime = v_prime/np.linalg.norm(v_prime) # create unit vector\n",
    "    E_prime[K[ii]] = v_prime \n",
    "\n",
    "    if (ii%N10 == 0) or (ii == N-1):\n",
    "        print(f\"Finished with {ii+1} embeddings out of {N} ({round(100*ii/N)}% done)\")\n",
    "\n",
    "\n",
    "# save as new pickle\n",
    "print(\"Saving new pickle ...\")\n",
    "embeddingName = '/path/to/your/data/Embedding-Latest-Isotropic.pkl'\n",
    "with open(embeddingName, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([E_prime,mu,U], f)\n",
    "    print(embeddingName)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "# When working with live data with a new embedding from ada-002, be sure to tranform it first with this function before comparing it\n",
    "#\n",
    "# def projectEmbedding(v,mu,U):\n",
    "#     v = np.array(v)\n",
    "#     v_tilde = v - mu\n",
    "#     v_projection = np.zeros(len(v)) # start to build the projection\n",
    "#     # project the original embedding onto the PCA basis vectors, use only first D dimensions\n",
    "#     for u in U:\n",
    "#         v_jj = np.dot(u,v) # scaler\n",
    "#         v_projection += v_jj*u # vector\n",
    "#     v_prime = v_tilde - v_projection # final embedding vector\n",
    "#     v_prime = v_prime/np.linalg.norm(v_prime) # create unit vector\n",
    "#     return v_prime "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
