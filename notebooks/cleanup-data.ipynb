{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- https://github.com/elisno/outlier_mnli/blob/main/outlier_mnli.ipynb\n",
    "- https://towardsdatascience.com/understanding-outliers-in-text-data-with-transformers-cleanlab-and-topic-modeling-db3585415a19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urlparse\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "embeddings_location = '../page-embeddings.pkl'\n",
    "outlier_scores_location = 'page-embeddings-outlier-scores.pkl'\n",
    "\n",
    "with open(embeddings_location, \"rb\") as reader:\n",
    "    cache_data = pickle.load(reader)\n",
    "    sections = cache_data['sections']\n",
    "    corpus_embeddings = cache_data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OOD estimator based on provided features ...\n"
     ]
    }
   ],
   "source": [
    "ood = OutOfDistribution()\n",
    "train_outlier_scores = ood.fit_score(features=corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outlier_scores_location, \"wb\") as writer:\n",
    "    pickle.dump({'scores': train_outlier_scores}, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outlier_scores_location, \"rb\") as reader:\n",
    "    cache_data = pickle.load(reader)\n",
    "    train_outlier_scores = cache_data['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_sections = np.array(sections)\n",
    "numpy_embeddings = np.array(corpus_embeddings)\n",
    "\n",
    "top_train_outlier_idxs = (train_outlier_scores).argsort()[:30]\n",
    "outlier_sections = numpy_sections[top_train_outlier_idxs]\n",
    "\n",
    "df = pd.DataFrame.from_records(pd.json_normalize(outlier_sections, sep='_'))\n",
    "df['score'] = train_outlier_scores[top_train_outlier_idxs]\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(train_outlier_scores, 2.5)\n",
    "\n",
    "plt_range = [train_outlier_scores.min(), train_outlier_scores.max()]\n",
    "\n",
    "counts, bins = np.histogram(train_outlier_scores, range=plt_range, bins=50)\n",
    "diagram = plt.stairs(counts, bins)\n",
    "plt.axvline(threshold, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ids = train_outlier_scores.argsort()\n",
    "scores = train_outlier_scores[sorted_ids]\n",
    "outlier_ids = sorted_ids[scores < threshold]\n",
    "rest_ids = sorted_ids[scores >= threshold]\n",
    "anomaly_ids = sorted_ids[scores > 0.999]\n",
    "exclusive_ids = sorted_ids[np.logical_and(threshold <= scores, scores <= 0.999)]\n",
    "\n",
    "outlier_sections = numpy_sections[outlier_ids]\n",
    "outlier_embeddings = numpy_embeddings[outlier_ids]\n",
    "outlier_scores = scores[outlier_ids]\n",
    "\n",
    "rest_sections = numpy_sections[rest_ids]\n",
    "rest_embeddings = numpy_embeddings[rest_ids]\n",
    "rest_scores = scores[rest_ids]\n",
    "\n",
    "anomaly_sections = numpy_sections[anomaly_ids]\n",
    "anomaly_embeddings = numpy_embeddings[anomaly_ids]\n",
    "anomaly_scores = scores[anomaly_ids]\n",
    "\n",
    "exclusive_sections = numpy_sections[exclusive_ids]\n",
    "exclusive_embeddings = numpy_embeddings[exclusive_ids]\n",
    "exclusive_scores = scores[exclusive_ids]\n",
    "\n",
    "df = pd.DataFrame.from_records(pd.json_normalize(outlier_sections, sep='_'))\n",
    "df['score'] = train_outlier_scores[outlier_ids]\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outlier_embeddings.pkl', \"wb\") as writer:\n",
    "    pickle.dump({'sections': outlier_sections, 'embeddings': outlier_embeddings}, writer)\n",
    "\n",
    "with open('rest_embeddings.pkl', \"wb\") as writer:\n",
    "    pickle.dump({'sections': rest_sections, 'embeddings': rest_embeddings}, writer)\n",
    "\n",
    "with open('anomaly_embeddings.pkl', \"wb\") as writer:\n",
    "    pickle.dump({'sections': anomaly_sections, 'embeddings': anomaly_embeddings}, writer)\n",
    "\n",
    "with open('exclusive_embeddings.pkl', \"wb\") as writer:\n",
    "    pickle.dump({'sections': exclusive_sections, 'embeddings': exclusive_embeddings}, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_umap_fit = UMAP(n_components=3, n_neighbors=8, random_state=42)\n",
    "outlier_embeddings_umap = outlier_umap_fit.fit_transform(outlier_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier = pd.DataFrame.from_records(pd.json_normalize(outlier_sections, sep='_'))\n",
    "df_outlier['score'] = train_outlier_scores[outlier_ids]\n",
    "df_outlier['content'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df_outlier['x'] = outlier_embeddings_umap[:, 0]\n",
    "df_outlier['y'] = outlier_embeddings_umap[:, 1]\n",
    "df_outlier['z'] = outlier_embeddings_umap[:, 2]\n",
    "df_outlier['domain'] = df_outlier['page_url'].apply(lambda x: urlparse(x).netloc)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_outlier, x='x', y='y', z='z',\n",
    "    color=df_outlier.domain, labels={'color': 'domain'}, hover_data=['content'],\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()\n",
    "\n",
    "df_outlier.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer_outlier_umap_fit = UMAP(n_components=2, n_neighbors=8, random_state=42)\n",
    "clusterer_outlier_embeddings_umap = clusterer_outlier_umap_fit.fit_transform(outlier_embeddings)\n",
    "\n",
    "clusterer_outlier = HDBSCAN(min_cluster_size=6, min_samples=4)\n",
    "clusterer_outlier.fit(clusterer_outlier_embeddings_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "outlier_x_plot, outlier_y_plot = clusterer_outlier_embeddings_umap[:, 0], clusterer_outlier_embeddings_umap[:, 1]\n",
    "outlier_domain_labels = {k: v for v, k in enumerate(df_outlier['domain'].unique())}\n",
    "outlier_assigned_labels = np.array([outlier_domain_labels.get(x, 0) for x in df_outlier['domain']])\n",
    "\n",
    "for i, domain in enumerate(df_outlier['domain'].unique()):\n",
    "    x, y = outlier_x_plot[outlier_assigned_labels == i], outlier_y_plot[outlier_assigned_labels == i]\n",
    "    plt.scatter(x, y, label=domain)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "clusterer_outlier_labels = clusterer_outlier.labels_\n",
    "clusterer_outlier.condensed_tree_.plot(select_clusters=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in np.unique(clusterer_outlier_labels):\n",
    "    if i != -1:\n",
    "        x, y = outlier_x_plot[clusterer_outlier_labels == i], outlier_y_plot[clusterer_outlier_labels == i]\n",
    "        plt.scatter(x, y, label=f\"cluster {i}\")\n",
    "\n",
    "x, y = outlier_x_plot[clusterer_outlier_labels == -1], outlier_y_plot[clusterer_outlier_labels == -1]\n",
    "plt.scatter(x, y, label=\"outliers\", color=\"gray\", alpha=0.15)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_umap_fit = UMAP(n_components=3, n_neighbors=8, random_state=42)\n",
    "rest_embeddings_umap = rest_umap_fit.fit_transform(rest_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = pd.DataFrame.from_records(pd.json_normalize(rest_sections, sep='_'))\n",
    "df_rest['score'] = train_outlier_scores[rest_ids]\n",
    "df_rest['content'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df_rest['x'] = rest_embeddings_umap[:, 0]\n",
    "df_rest['y'] = rest_embeddings_umap[:, 1]\n",
    "df_rest['z'] = rest_embeddings_umap[:, 2]\n",
    "df_rest['domain'] = df_rest['page_url'].apply(lambda x: urlparse(x).netloc)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_rest, x='x', y='y', z='z',\n",
    "    color=df_rest.domain, labels={'color': 'domain'}, hover_data=['content'],\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()\n",
    "\n",
    "df_rest.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer_rest_umap_fit = UMAP(n_components=2, n_neighbors=8, random_state=42)\n",
    "clusterer_rest_embeddings_umap = clusterer_rest_umap_fit.fit_transform(rest_embeddings)\n",
    "\n",
    "clusterer_rest = HDBSCAN(min_cluster_size=6, min_samples=4)\n",
    "clusterer_rest.fit(clusterer_rest_embeddings_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "rest_x_plot, rest_y_plot = clusterer_rest_embeddings_umap[:, 0], clusterer_rest_embeddings_umap[:, 1]\n",
    "rest_domain_labels = {k: v for v, k in enumerate(df_rest['domain'].unique())}\n",
    "rest_assigned_labels = np.array([rest_domain_labels.get(x, 0) for x in df_rest['domain']])\n",
    "\n",
    "for i, domain in enumerate(df_rest['domain'].unique()):\n",
    "    x, y = rest_x_plot[rest_assigned_labels == i], rest_y_plot[rest_assigned_labels == i]\n",
    "    plt.scatter(x, y, label=domain)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "clusterer_rest_labels = clusterer_rest.labels_\n",
    "clusterer_rest.condensed_tree_.plot(select_clusters=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in np.unique(clusterer_rest_labels):\n",
    "    if i != -1:\n",
    "        x, y = rest_x_plot[clusterer_rest_labels == i], rest_y_plot[clusterer_rest_labels == i]\n",
    "        plt.scatter(x, y, label=f\"cluster {i}\")\n",
    "\n",
    "x, y = rest_x_plot[clusterer_rest_labels == -1], rest_y_plot[clusterer_rest_labels == -1]\n",
    "plt.scatter(x, y, label=\"outliers\", color=\"gray\", alpha=0.15)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_umap_fit = UMAP(n_components=3, n_neighbors=8, random_state=42)\n",
    "anomaly_embeddings_umap = anomaly_umap_fit.fit_transform(anomaly_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly = pd.DataFrame.from_records(pd.json_normalize(anomaly_sections, sep='_'))\n",
    "df_anomaly['score'] = train_outlier_scores[anomaly_ids]\n",
    "df_anomaly['content'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df_anomaly['x'] = anomaly_embeddings_umap[:, 0]\n",
    "df_anomaly['y'] = anomaly_embeddings_umap[:, 1]\n",
    "df_anomaly['z'] = anomaly_embeddings_umap[:, 2]\n",
    "df_anomaly['domain'] = df_anomaly['page_url'].apply(lambda x: urlparse(x).netloc)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_anomaly, x='x', y='y', z='z',\n",
    "    color=df_anomaly.domain, labels={'color': 'domain'}, hover_data=['content'],\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()\n",
    "\n",
    "df_anomaly.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer_anomaly_umap_fit = UMAP(n_components=2, n_neighbors=8, random_state=42)\n",
    "clusterer_anomaly_embeddings_umap = clusterer_anomaly_umap_fit.fit_transform(anomaly_embeddings)\n",
    "\n",
    "clusterer_anomaly = HDBSCAN(min_cluster_size=6, min_samples=4)\n",
    "clusterer_anomaly.fit(clusterer_anomaly_embeddings_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "anomaly_x_plot, anomaly_y_plot = clusterer_anomaly_embeddings_umap[:, 0], clusterer_anomaly_embeddings_umap[:, 1]\n",
    "anomaly_domain_labels = {k: v for v, k in enumerate(df_anomaly['domain'].unique())}\n",
    "anomaly_assigned_labels = np.array([anomaly_domain_labels.get(x, 0) for x in df_anomaly['domain']])\n",
    "\n",
    "for i, domain in enumerate(df_anomaly['domain'].unique()):\n",
    "    x, y = anomaly_x_plot[anomaly_assigned_labels == i], anomaly_y_plot[anomaly_assigned_labels == i]\n",
    "    plt.scatter(x, y, label=domain)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "clusterer_anomaly_labels = clusterer_anomaly.labels_\n",
    "clusterer_anomaly.condensed_tree_.plot(select_clusters=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in np.unique(clusterer_anomaly_labels):\n",
    "    if i != -1:\n",
    "        x, y = anomaly_x_plot[clusterer_anomaly_labels == i], anomaly_y_plot[clusterer_anomaly_labels == i]\n",
    "        plt.scatter(x, y, label=f\"cluster {i}\")\n",
    "\n",
    "x, y = anomaly_x_plot[clusterer_anomaly_labels == -1], anomaly_y_plot[clusterer_anomaly_labels == -1]\n",
    "plt.scatter(x, y, label=\"outliers\", color=\"gray\", alpha=0.15)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusive_umap_fit = UMAP(n_components=3, n_neighbors=8, random_state=42)\n",
    "exclusive_embeddings_umap = exclusive_umap_fit.fit_transform(exclusive_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exclusive = pd.DataFrame.from_records(pd.json_normalize(exclusive_sections, sep='_'))\n",
    "df_exclusive['score'] = train_outlier_scores[exclusive_ids]\n",
    "df_exclusive['content'].apply(lambda x: x.replace('\\n', ' ').strip())\n",
    "df_exclusive['x'] = exclusive_embeddings_umap[:, 0]\n",
    "df_exclusive['y'] = exclusive_embeddings_umap[:, 1]\n",
    "df_exclusive['z'] = exclusive_embeddings_umap[:, 2]\n",
    "df_exclusive['domain'] = df_exclusive['page_url'].apply(lambda x: urlparse(x).netloc)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_exclusive, x='x', y='y', z='z',\n",
    "    color=df_exclusive.domain, labels={'color': 'domain'}, hover_data=['content'],\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()\n",
    "\n",
    "df_exclusive.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer_exclusive_umap_fit = UMAP(n_components=2, n_neighbors=8, random_state=42)\n",
    "clusterer_exclusive_embeddings_umap = clusterer_exclusive_umap_fit.fit_transform(exclusive_embeddings)\n",
    "\n",
    "clusterer_exclusive = HDBSCAN(min_cluster_size=6, min_samples=4)\n",
    "clusterer_exclusive.fit(clusterer_exclusive_embeddings_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "exclusive_x_plot, exclusive_y_plot = clusterer_exclusive_embeddings_umap[:, 0], clusterer_exclusive_embeddings_umap[:, 1]\n",
    "exclusive_domain_labels = {k: v for v, k in enumerate(df_exclusive['domain'].unique())}\n",
    "exclusive_assigned_labels = np.array([exclusive_domain_labels.get(x, 0) for x in df_exclusive['domain']])\n",
    "\n",
    "for i, domain in enumerate(df_exclusive['domain'].unique()):\n",
    "    x, y = exclusive_x_plot[exclusive_assigned_labels == i], exclusive_y_plot[exclusive_assigned_labels == i]\n",
    "    plt.scatter(x, y, label=domain)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "clusterer_exclusive_labels = clusterer_exclusive.labels_\n",
    "clusterer_exclusive.condensed_tree_.plot(select_clusters=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in np.unique(clusterer_exclusive_labels):\n",
    "    if i != -1:\n",
    "        x, y = exclusive_x_plot[clusterer_exclusive_labels == i], exclusive_y_plot[clusterer_exclusive_labels == i]\n",
    "        plt.scatter(x, y, label=f\"cluster {i}\")\n",
    "\n",
    "x, y = exclusive_x_plot[clusterer_exclusive_labels == -1], exclusive_y_plot[clusterer_exclusive_labels == -1]\n",
    "plt.scatter(x, y, label=\"outliers\", color=\"gray\", alpha=0.15)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
